#BEGIN_LEGAL
#
#Copyright (c) 2019 Intel Corporation
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#  
#END_LEGAL
AVX_INSTRUCTIONS()::


# DEST in MODRM.REG
# BASE in SIB.base
# INDEX in SIB.index
# MASK in VEX.VVVV   --  NOTE mask is a signed integer!!!

#                    VL = 128                        VL = 256
#            dest/mask   index  memsz        dest/mask   index   memsz
# qps/qd      xmm       xmm      2*32=64b      xmm*       ymm*    4*32=128b
# dps/dd      xmm       xmm      4*32=128b     ymm        ymm     8*32=256b
# dpd/dq      xmm       xmm      2*64=128b     ymm*       xmm*    4*64=256b
# qpd/qq      xmm       xmm      2*64=128b     ymm        ymm     4*64=256b



{
ICLASS    : VGATHERDPD
CPL       : 3
CATEGORY  : AVX2GATHER
EXTENSION : AVX2GATHER
ATTRIBUTES : gather DWORD_INDICES ELEMENT_SIZE_q SPECIAL_AGEN_REQUIRED
EXCEPTIONS: avx-type-12


# VL = 256 - when data/mask differ from index size see asterisks in above chart.
PATTERN : VV1 0x92   VL256 V66 V0F38 W1 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=YMM_R():crw:qq:f64   MEM0:r:q:f64 REG1=YMM_N():rw:qq:i64
IFORM: VGATHERDPD_YMMf64_MEMf64_YMMi64_VL256

# VL = 128 - index, mask and dest are all XMMs
PATTERN : VV1 0x92   VL128 V66 V0F38 W1 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=XMM_R():crw:dq:f64   MEM0:r:q:f64 REG1=XMM_N():rw:dq:i64
IFORM: VGATHERDPD_XMMf64_MEMf64_XMMi64_VL128

COMMENT: mask reg is zeroized on normal termination. mask_sz=data_sz
}
{
ICLASS    : VGATHERDPS
CPL       : 3
CATEGORY  : AVX2GATHER
EXTENSION : AVX2GATHER
ATTRIBUTES : gather DWORD_INDICES ELEMENT_SIZE_d SPECIAL_AGEN_REQUIRED
EXCEPTIONS: avx-type-12


# VL = 256 - when data/mask differ from index size see asterisks in above chart.
PATTERN : VV1 0x92   VL256 V66 V0F38 W0 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_YMM() eanot16
OPERANDS  : REG0=YMM_R():crw:qq:f32   MEM0:r:d:f32 REG1=YMM_N():rw:qq:i32
IFORM: VGATHERDPS_YMMf32_MEMf32_YMMi32_VL256

# VL = 128 - index, mask and dest are all XMMs
PATTERN : VV1 0x92   VL128 V66 V0F38 W0 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=XMM_R():crw:dq:f32   MEM0:r:d:f32 REG1=XMM_N():rw:dq:i32
IFORM: VGATHERDPS_XMMf32_MEMf32_XMMi32_VL128

COMMENT: mask reg is zeroized on normal termination. mask_sz=data_sz
}
{
ICLASS    : VGATHERQPD
CPL       : 3
CATEGORY  : AVX2GATHER
EXTENSION : AVX2GATHER
ATTRIBUTES : gather QWORD_INDICES ELEMENT_SIZE_q SPECIAL_AGEN_REQUIRED
EXCEPTIONS: avx-type-12

# VL = 256 - when data/mask differ from index size see asterisks in above chart.
PATTERN : VV1 0x93   VL256 V66 V0F38 W1 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_YMM() eanot16
OPERANDS  : REG0=YMM_R():crw:qq:f64   MEM0:r:q:f64 REG1=YMM_N():rw:qq:i64
IFORM: VGATHERQPD_YMMf64_MEMf64_YMMi64_VL256

# VL = 128 - index, mask and dest are all XMMs
PATTERN : VV1 0x93   VL128 V66 V0F38 W1 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=XMM_R():crw:dq:f64   MEM0:r:q:f64 REG1=XMM_N():rw:dq:i64
IFORM: VGATHERQPD_XMMf64_MEMf64_XMMi64_VL128

COMMENT: mask reg is zeroized on normal termination. mask_sz=data_sz
}
{
ICLASS    : VGATHERQPS
CPL       : 3
CATEGORY  : AVX2GATHER
EXTENSION : AVX2GATHER
ATTRIBUTES : gather QWORD_INDICES ELEMENT_SIZE_d SPECIAL_AGEN_REQUIRED
EXCEPTIONS: avx-type-12


# VL = 256 - when data/mask differ from index size see asterisks in above chart.
PATTERN : VV1 0x93   VL256 V66 V0F38   W0 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_YMM() eanot16
OPERANDS  : REG0=XMM_R():crw:dq:f32   MEM0:r:d:f32 REG1=XMM_N():rw:dq:i32
IFORM: VGATHERQPS_XMMf32_MEMf32_XMMi32_VL256

# VL = 128 - index, mask and dest are all XMMs
PATTERN : VV1 0x93   VL128 V66 V0F38 W0 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=XMM_R():crw:q:f32   MEM0:r:d:f32 REG1=XMM_N():rw:q:i32
IFORM: VGATHERQPS_XMMf32_MEMf32_XMMi32_VL128

COMMENT: mask reg is zeroized on normal termination. mask_sz=data_sz
}

{
ICLASS    : VPGATHERDQ
CPL       : 3
CATEGORY  : AVX2GATHER
EXTENSION : AVX2GATHER
ATTRIBUTES : gather DWORD_INDICES ELEMENT_SIZE_q SPECIAL_AGEN_REQUIRED
EXCEPTIONS: avx-type-12

# VL = 256 - when data/mask differ from index size see asterisks in above chart.
PATTERN : VV1 0x90   VL256 V66 V0F38 W1 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=YMM_R():crw:qq:u64   MEM0:r:q:u64 REG1=YMM_N():rw:qq:i64
IFORM: VPGATHERDQ_YMMu64_MEMq_YMMi64_VL256

# VL = 128 - index, mask and dest are all XMMs
PATTERN : VV1 0x90   VL128 V66 V0F38 W1 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=XMM_R():crw:dq:u64   MEM0:r:q:u64 REG1=XMM_N():rw:dq:i64
IFORM: VPGATHERDQ_XMMu64_MEMq_XMMi64_VL128

COMMENT: mask reg is zeroized on normal termination. mask_sz=data_sz
}
{
ICLASS    : VPGATHERDD
CPL       : 3
CATEGORY  : AVX2GATHER
EXTENSION : AVX2GATHER
ATTRIBUTES : gather DWORD_INDICES ELEMENT_SIZE_d SPECIAL_AGEN_REQUIRED
EXCEPTIONS: avx-type-12

# VL = 256 - when data/mask differ from index size see asterisks in above chart.
PATTERN : VV1 0x90   VL256 V66 V0F38 W0 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_YMM() eanot16
OPERANDS  : REG0=YMM_R():crw:qq:u32   MEM0:r:d:u32 REG1=YMM_N():rw:qq:i32
IFORM: VPGATHERDD_YMMu32_MEMd_YMMi32_VL256

# VL = 128 - index, mask and dest are all XMMs
PATTERN : VV1 0x90   VL128 V66 V0F38 W0 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=XMM_R():crw:dq:u32   MEM0:r:d:u32 REG1=XMM_N():rw:dq:i32
IFORM: VPGATHERDD_XMMu32_MEMd_XMMi32_VL128

COMMENT: mask reg is zeroized on normal termination. mask_sz=data_sz
}
{
ICLASS    : VPGATHERQQ
CPL       : 3
CATEGORY  : AVX2GATHER
EXTENSION : AVX2GATHER
ATTRIBUTES : gather QWORD_INDICES ELEMENT_SIZE_q SPECIAL_AGEN_REQUIRED
EXCEPTIONS: avx-type-12

# VL = 256 - when data/mask differ from index size see asterisks in above chart.
PATTERN : VV1 0x91   VL256 V66 V0F38 W1 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_YMM() eanot16
OPERANDS  : REG0=YMM_R():crw:qq:u64   MEM0:r:q:u64 REG1=YMM_N():rw:qq:i64
IFORM: VPGATHERQQ_YMMu64_MEMq_YMMi64_VL256

# VL = 128 - index, mask and dest are all XMMs
PATTERN : VV1 0x91   VL128 V66 V0F38 W1 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=XMM_R():crw:dq:u64   MEM0:r:q:u64 REG1=XMM_N():rw:dq:i64
IFORM: VPGATHERQQ_XMMu64_MEMq_XMMi64_VL128

COMMENT: mask reg is zeroized on normal termination. mask_sz=data_sz
}
{
ICLASS    : VPGATHERQD
CPL       : 3
CATEGORY  : AVX2GATHER
EXTENSION : AVX2GATHER
ATTRIBUTES : gather QWORD_INDICES ELEMENT_SIZE_d SPECIAL_AGEN_REQUIRED
EXCEPTIONS: avx-type-12

# VL = 256 - when data/mask differ from index size see asterisks in above chart.
PATTERN : VV1 0x91   VL256 V66 V0F38 W0 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_YMM() eanot16
OPERANDS  : REG0=XMM_R():crw:dq:u32   MEM0:r:d:u32 REG1=XMM_N():rw:dq:i32
IFORM: VPGATHERQD_XMMu32_MEMd_XMMi32_VL256

# VL = 128 - index, mask and dest are all XMMs
PATTERN : VV1 0x91   VL128 V66 V0F38 W0 MOD[mm] MOD!=3 REG[rrr] RM[nnn] RM=4 VMODRM_XMM() eanot16
OPERANDS  : REG0=XMM_R():crw:q:u32   MEM0:r:d:u32 REG1=XMM_N():rw:q:i32
IFORM: VPGATHERQD_XMMu32_MEMd_XMMi32_VL128

COMMENT: mask reg is zeroized on normal termination. mask_sz=data_sz
}

