#BEGIN_LEGAL
#
#Copyright (c) 2019 Intel Corporation
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#  
#END_LEGAL

KNC_EVEX_INSTRUCTIONS()::


{
ICLASS    : VADDPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x58 V0F VNP  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x58 V0F VNP  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x58 V0F VNP  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VADDPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x58 V0F V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x58 V0F V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x58 V0F V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VGMAXPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x53 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x53 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x53 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VGMAXPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x53 V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x53 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x53 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=SAEC
}
{
ICLASS    : VGMINPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x52 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x52 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x52 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VGMINPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x52 V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x52 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x52 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=SAEC
}
{
ICLASS    : VBLENDMPS
CPL       : 3
CATEGORY  : BLEND
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX MASK_AS_CONTROL
PATTERN   : KVV 0x65 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x65 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x65 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VBLENDMPD
CPL       : 3
CATEGORY  : BLEND
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x65 V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x65 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x65 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}


{
ICLASS    : VADDNPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x50 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x50 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x50 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VADDNPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x50 V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x50 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x50 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}


{
ICLASS    : VSUBPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x5C V0F VNP  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x5C V0F VNP  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x5C V0F VNP  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VSUBPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x5C V0F V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x5C V0F V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x5C V0F V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VSUBRPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x6D V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x6D V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x6D V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VSUBRPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x6D V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x6D V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x6D V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VMULPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x59 V0F VNP  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x59 V0F VNP  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x59 V0F VNP  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VMULPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x59 V0F V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x59 V0F V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x59 V0F V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VGMAXABSPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x51 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x51 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x51 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=SAEC
}

{
ICLASS    : VFMADD233PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xA4 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32_LIMITED()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xA4 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xA4 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFMADD132PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x98 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x98 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x98 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFMADD132PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x98 V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x98 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x98 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VFMADD213PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xA8 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xA8 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xA8 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFMADD213PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xA8 V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xA8 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xA8 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VFMADD231PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xB8 V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xB8 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xB8 V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFMADD231PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xB8 V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xB8 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xB8 V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFNMADD132PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x9C V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x9C V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x9C V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFNMADD132PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x9C V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x9C V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x9C V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VFNMADD213PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xAC V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xAC V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xAC V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFNMADD213PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xAC V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xAC V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xAC V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VFNMADD231PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xBC V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xBC V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xBC V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFNMADD231PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xBC V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xBC V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xBC V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFMSUB132PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x9A V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x9A V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x9A V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFMSUB132PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x9A V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x9A V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x9A V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VFMSUB213PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xAA V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xAA V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xAA V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFMSUB213PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xAA V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xAA V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xAA V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VFMSUB231PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xBA V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xBA V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xBA V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFMSUB231PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xBA V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xBA V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xBA V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFNMSUB132PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x9E V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x9E V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x9E V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFNMSUB132PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x9E V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x9E V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x9E V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VFNMSUB213PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xAE V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xAE V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xAE V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFNMSUB213PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xAE V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xAE V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xAE V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS    : VFNMSUB231PS
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xBE V0F38 V66  REXW=0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xBE V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xBE V0F38 V66  REXW=0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}

{
ICLASS    : VFNMSUB231PD
CPL       : 3
CATEGORY  : UFMA
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR   KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xBE V0F38 V66  REXW=1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xBE V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xBE V0F38 V66  REXW=1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}



{
ICLASS    : VMOVAPS
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  KNC_VMOV  REQUIRES_ALIGNMENT MASKOP_EVEX
# load from memory
PATTERN   : KVV 0x28 V0F VNP  REXW=0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register
PATTERN   : KVV 0x28 V0F VNP  REXW=0 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=REGSWIZ

# load from register
PATTERN   : KVV 0x28 V0F VNP  REXW=0 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32
}
{
ICLASS    : VMOVAPD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  KNC_VMOV KNC_F64  REQUIRES_ALIGNMENT MASKOP_EVEX
# load from memory
PATTERN   : KVV 0x28 V0F V66  REXW=1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register
PATTERN   : KVV 0x28 V0F V66  REXW=1 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn]  NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=REGSWIZ

# load from register
PATTERN   : KVV 0x28 V0F V66  REXW=1 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn]  NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64
}
{
ICLASS    : VMOVAPS
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  KNC_VMOV  REQUIRES_ALIGNMENT MASKOP_EVEX
# store to memory
PATTERN   : KVV 0x29 V0F VNP  REXW=0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_FLT32()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zf32
}
{
ICLASS    : VMOVAPD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  KNC_VMOV KNC_F64  REQUIRES_ALIGNMENT MASKOP_EVEX
# store to memory, no legal down convert.
PATTERN   : KVV 0x29 V0F V66  REXW=1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  DNCONVERT_FLT64()
OPERANDS  : MEM0:w:zf64:TXT=NT  REG0=MASK1():r:mskw REG1=ZMM_R3():r:zf64
}



##






##





{
ICLASS    : VMOVDQA32
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_VMOV REQUIRES_ALIGNMENT MASKOP_EVEX
# load from memory
PATTERN   : KVV 0x6F  V0F V66  REXW=0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register
PATTERN   : KVV 0x6F  V0F V66  REXW=0 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zd:TXT=REGSWIZ

# load from register
PATTERN   : KVV 0x6F  V0F V66  REXW=0 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zd
}
{
ICLASS    : VMOVDQA64
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_VMOV KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX
# load from memory
PATTERN   : KVV 0x6F  V0F V66  REXW=1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zq REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register
PATTERN   : KVV 0x6F  V0F V66  REXW=1 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn]  NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zq REG1=MASK1():r:mskw REG2=ZMM_B3():r:zq:TXT=REGSWIZ

# load from register
PATTERN   : KVV 0x6F  V0F V66  REXW=1 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn]  NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zq REG1=MASK1():r:mskw REG2=ZMM_B3():r:zq
}
{
ICLASS    : VMOVDQA32
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_VMOV REQUIRES_ALIGNMENT MASKOP_EVEX
# store to memory
PATTERN   : KVV 0x7F  V0F V66  REXW=0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_INT32()
OPERANDS  : MEM0:w:zv:TXT=NT:TXT=CONVERT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zd
}
{
ICLASS    : VMOVDQA64
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_VMOV KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX
# store to memory, no legal down convert.
PATTERN   : KVV 0x7F  V0F V66  REXW=1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  DNCONVERT_INT64()
OPERANDS  : MEM0:w:zq:TXT=NT  REG0=MASK1():r:mskw REG1=ZMM_R3():r:zq
}























# this one writes the mask
{
ICLASS    : VPADDSETSD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xCD V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():rw:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xCD V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():rw:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xCD V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():rw:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}

{
ICLASS    : VFIXUPNANPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x55 V0F38 REXW=1 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x55 V0F38 REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x55 V0F38 REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=SAEC
}
{
ICLASS    : VFIXUPNANPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x55 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x55 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x55 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=SAEC
}
{
ICLASS    : VSCALEPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x84 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x84 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x84 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPMADD231D
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xB5 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xB5 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xB5 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPMADD233D
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xB4 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32_LIMITED()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xB4 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xB4 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPMAXSD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x3D V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x3D V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x3D V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPMAXUD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x3F V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x3F V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x3F V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPMINSD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x39 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x39 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x39 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPMINUD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x3B V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x3B V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x3B V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}

{
ICLASS    : VPBLENDMD
CPL       : 3
CATEGORY  : BLEND
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX MASK_AS_CONTROL

PATTERN   : KVV 0x64 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x64 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x64 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPBLENDMQ
CPL       : 3
CATEGORY  : BLEND
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX MASK_AS_CONTROL

PATTERN   : KVV 0x64 V0F38 REXW=1 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x64 V0F38 REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x64 V0F38 REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64
}
{
ICLASS    : VPANDD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xDB V0F REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xDB V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xDB V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPANDQ
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xDB V0F REXW=1 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xDB V0F REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xDB V0F REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64
}
{
ICLASS    : VPANDND
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xDF V0F REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xDF V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xDF V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPANDNQ
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xDF V0F REXW=1 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xDF V0F REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xDF V0F REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64
}
{
ICLASS    : VPORD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xEB V0F REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xEB V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xEB V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPORQ
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xEB V0F REXW=1 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xEB V0F REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xEB V0F REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64
}
{
ICLASS    : VPXORD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xEF V0F REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xEF V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xEF V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPXORQ
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xEF V0F REXW=1 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xEF V0F REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0xEF V0F REXW=1 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64
}


{
ICLASS    : VPADDD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xFE V0F REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xFE V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xFE V0F REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPSUBD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xFA V0F V66 REXW=0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0xFA V0F V66 REXW=0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0xFA V0F V66 REXW=0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}
{
ICLASS    : VPSUBRD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x6C V0F38 V66 REXW=0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x6C V0F38 V66 REXW=0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x6C V0F38 V66 REXW=0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}


{
ICLASS    : VPMULLD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x40 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x40 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x40 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}

{
ICLASS    : VPMULHD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x87 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x87 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x87 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}

{
ICLASS    : VPMULHUD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_INT REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x86 V0F38 REXW=0 V66  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT


PATTERN   : KVV 0x86 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ
PATTERN   : KVV 0x86 V0F38 REXW=0 V66  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}

##








###




{
ICLASS    : VPSLLD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES: REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[0b11]  MOD=3 REG[0b110] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32:TXT=REGSWIZ IMM0:r:b

PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[0b11]  MOD=3 REG[0b110] RM[nnn] UIMM8() NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32 IMM0:r:b

PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[mm]  MOD!=3 REG[0b110] RM[nnn] MODRM() UIMM8() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

}
{
ICLASS    : VPSRAD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES: REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[0b11]  MOD=3 REG[0b100] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32:TXT=REGSWIZ IMM0:r:b

PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[0b11]  MOD=3 REG[0b100] RM[nnn] UIMM8() NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32 IMM0:r:b

PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[mm]  MOD!=3 REG[0b100] RM[nnn] MODRM() UIMM8() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

}
{
ICLASS    : VPSRLD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES: REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[0b11]  MOD=3 REG[0b010] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32:TXT=REGSWIZ IMM0:r:b

PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[0b11]  MOD=3 REG[0b010] RM[nnn] UIMM8() NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32 IMM0:r:b

PATTERN   : KVV 0x72 V0F V66  REXW=0  MOD[mm]  MOD!=3 REG[0b010] RM[nnn] MODRM() UIMM8() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_N3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

}







{
ICLASS    : VPSLLVD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES: REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x47 V0F38 V66  REXW=0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x47 V0F38 V66  REXW=0  MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd  REG3=ZMM_B3():r:zd

PATTERN   : KVV 0x47 V0F38 V66  REXW=0  MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd  REG3=ZMM_B3():r:zd:TXT=REGSWIZ
}


{
ICLASS    : VPSRAVD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES: REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x46 V0F38 V66  REXW=0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x46 V0F38 V66  REXW=0  MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd  REG3=ZMM_B3():r:zd

PATTERN   : KVV 0x46 V0F38 V66  REXW=0  MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd  REG3=ZMM_B3():r:zd:TXT=REGSWIZ
}


{
ICLASS    : VPSRLVD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES: REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x45 V0F38 V66  REXW=0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x45 V0F38 V66  REXW=0  MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd  REG3=ZMM_B3():r:zd

PATTERN   : KVV 0x45 V0F38 V66  REXW=0  MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd  REG3=ZMM_B3():r:zd:TXT=REGSWIZ
}


###




{
ICLASS    : VPSHUFD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : NOSWIZ REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x70 V0F V66  REXW=0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() NOSWIZD()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  MEM0:r:zd:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0x70 V0F V66  REXW=0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd  IMM0:r:b

PATTERN   : KVV 0x70 V0F V66  REXW=0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd IMM0:r:b
}
{
ICLASS    : VPERMF32X4
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : NOSWIZ REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x07 V0F3A V66  REXW=0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() NOSWIZD()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  MEM0:r:zd:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0x07 V0F3A V66  REXW=0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd  IMM0:r:b

PATTERN   : KVV 0x07 V0F3A V66  REXW=0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd IMM0:r:b
}

#########





{
ICLASS    : VCVTPS2PD
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x5A V0F REXW=0 VNP    NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32_HALF()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x5A V0F REXW=0 VNP   NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32:TXT=REGSWIZ

PATTERN   : KVV 0x5A V0F REXW=0 VNP   NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32:TXT=SAEC
}


{
ICLASS    : VGETEXPPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x42 V0F38 V66   W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x42 V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32:TXT=REGSWIZ

PATTERN   : KVV 0x42 V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf32:TXT=SAEC
}



{
ICLASS    : VGETEXPPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x42 V0F38 V66   W1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x42 V0F38 V66  W1  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=REGSWIZ

PATTERN   : KVV 0x42 V0F38 V66  W1  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=SAEC
}




{
ICLASS    : VCVTDQ2PD
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES: REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xE6 V0F W0 VF3    NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32_HALF()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0xE6 V0F W0 VF3   NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=REGSWIZ

PATTERN   : KVV 0xE6 V0F W0 VF3   NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64
}
{
ICLASS    : VCVTUDQ2PD
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES: REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x7A V0F W0 VF3    NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32_HALF()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x7A V0F W0 VF3   NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=REGSWIZ

PATTERN   : KVV 0x7A V0F W0 VF3   NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64
}





###########################



{
ICLASS    : VBROADCASTF32X4
CPL       : 3
CATEGORY  : BROADCAST
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x1A V0F38 V66 REXW=0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NELEM=4:SUPP EMX_BROADCAST_4TO16_32
}
{
ICLASS    : VBROADCASTSS
CPL       : 3
CATEGORY  : BROADCAST
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_FP MXCSR  REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x18 V0F38 V66 REXW=0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NELEM=1:SUPP EMX_BROADCAST_1TO16_32
}


{
ICLASS    : VBROADCASTSD
CPL       : 3
CATEGORY  : BROADCAST
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x19 V0F38 V66 REXW=1  REXW=1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NELEM=1:SUPP EMX_BROADCAST_1TO8_64
}
{
ICLASS    : VBROADCASTF64x4
CPL       : 3
CATEGORY  : BROADCAST
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x1B V0F38 V66 REXW=1  REXW=1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NELEM=4:SUPP EMX_BROADCAST_4TO8_64
}




#####



{
ICLASS    : VBROADCASTI32X4
CPL       : 3
CATEGORY  : BROADCAST
EXTENSION : KNCE
ATTRIBUTES : MEMONLY REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x5A V0F38 V66 REXW=0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zd:i32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NELEM=4:SUPP EMX_BROADCAST_4TO16_32
}
{
ICLASS    : VPBROADCASTD
CPL       : 3
CATEGORY  : BROADCAST
EXTENSION : KNCE
ATTRIBUTES : MEMONLY REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x58 V0F38 V66 REXW=0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zd:i32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NELEM=1:SUPP EMX_BROADCAST_1TO16_32
}


{
ICLASS    : VPBROADCASTQ
CPL       : 3
CATEGORY  : BROADCAST
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x59 V0F38 V66 REXW=1  REXW=1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zq:i64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NELEM=1:SUPP EMX_BROADCAST_1TO8_64
}
{
ICLASS    : VBROADCASTI64x4
CPL       : 3
CATEGORY  : BROADCAST
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_I64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x5B V0F38 V66 REXW=1  REXW=1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zq:i64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NELEM=4:SUPP EMX_BROADCAST_4TO8_64
}



###





{
ICLASS         : VADDSETSPS
CATEGORY       : KNC
EXTENSION      : KNCE
ATTRIBUTES     : KNC_FP MXCSR  MASKOP_EVEX
COMMENT        :
PATTERN        : KVV 0xCC V0F38 V66 W0   MOD[0b11] MOD=3 REG[uuu] RM[www] NR=0 REG_SWIZZLE32()
OPERANDS       : REG0=ZMM_R3():rw:zf32 REG1=MASK1():rw:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ

PATTERN        : KVV 0xCC V0F38 V66 W0   MOD[0b11] MOD=3 REG[uuu] RM[www] NR=1 ROUND() KNC_SAE()
OPERANDS       : REG0=ZMM_R3():rw:zf32 REG1=MASK1():rw:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=ROUNDC:TXT=SAEC
}
{
ICLASS         : VADDSETSPS
CATEGORY       : KNC
EXTENSION      : KNCE
ATTRIBUTES     : KNC_FP MXCSR REQUIRES_ALIGNMENT MASKOP_EVEX
COMMENT        :
PATTERN        : KVV 0xCC V0F38 V66 W0  MOD[mm] MOD!=3 REG[uuu] RM[rrr] MODRM() UPCONVERT_FLT32()
OPERANDS       : REG0=ZMM_R3():rw:zf32 REG1=MASK1():rw:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT
}






{
ICLASS    : VLOADUNPACKHD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : MEMONLY MASKADDR NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xD4 V0F38 VNP W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NO_SCALE_DISP8=1
}
{
ICLASS    : VLOADUNPACKLD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : MEMONLY MASKADDR NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xD0 V0F38 VNP W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT  NO_SCALE_DISP8=1
}



{
ICLASS    : VLOADUNPACKHPD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_FP MXCSR  MASKADDR KNC_F64 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xD5 V0F38 VNP W1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=NT   NO_SCALE_DISP8=1
}
{
ICLASS    : VLOADUNPACKLPD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_FP MXCSR  MASKADDR KNC_F64 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xD1 V0F38 VNP W1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=NT   NO_SCALE_DISP8=1
}



{
ICLASS    : VLOADUNPACKHPS
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_FP MXCSR  MASKADDR NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xD5 V0F38 VNP W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT   NO_SCALE_DISP8=1
}
{
ICLASS    : VLOADUNPACKLPS
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : MEMONLY KNC_FP MXCSR  MASKADDR NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xD1 V0F38 VNP W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_FLT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT   NO_SCALE_DISP8=1
}



{
ICLASS    : VLOADUNPACKHQ
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : MEMONLY MASKADDR KNC_I64 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xD4 V0F38 VNP W1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zq REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT   NO_SCALE_DISP8=1
}
{
ICLASS    : VLOADUNPACKLQ
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ATTRIBUTES : MEMONLY MASKADDR KNC_I64 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xD0 V0F38 VNP W1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zq REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT   NO_SCALE_DISP8=1
}




################
# v2 template  --- some have imm8
#



{
ICLASS    : VCMPPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
COMMENT   : NO ROUNDING FORM
ATTRIBUTES : KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xC2 V66 V0F  W1 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

PATTERN   : KVV 0xC2 V66 V0F  W1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=REGSWIZ IMM0:r:b
PATTERN   : KVV 0xC2 V66 V0F  W1 MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1  KNC_SAE()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf64 REG3=ZMM_B3():r:zf64:TXT=SAEC IMM0:r:b
}




{
ICLASS    : VCMPPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
COMMENT   : NO ROUNDING FORM
ATTRIBUTES : KNC_FP MXCSR REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xC2 VNP V0F  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT32()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

PATTERN   : KVV 0xC2 VNP V0F  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=REGSWIZ IMM0:r:b
PATTERN   : KVV 0xC2 VNP V0F  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1  KNC_SAE()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32:TXT=SAEC IMM0:r:b
}




{
ICLASS    : VPCMPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
COMMENT   : NO ROUNDING FORM
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x1F V66 V0F3A  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_INT32()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

PATTERN   : KVV 0x1F V66 V0F3A  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd:TXT=REGSWIZ IMM0:r:b
PATTERN   : KVV 0x1F V66 V0F3A  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1  SWIZ=0
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd IMM0:r:b
}



{
ICLASS    : VPCMPUD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
COMMENT   : NO ROUNDING FORM
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x1E V66 V0F3A  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_INT32()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zud MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

PATTERN   : KVV 0x1E V66 V0F3A  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zud REG3=ZMM_B3():r:zud:TXT=REGSWIZ IMM0:r:b
PATTERN   : KVV 0x1E V66 V0F3A  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1  SWIZ=0
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zud REG3=ZMM_B3():r:zud IMM0:r:b
}




{
ICLASS    : VPCMPEQD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
COMMENT   : NO ROUNDING FORM
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x76 V66 V0F  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT32()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x76 V66 V0F  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd:TXT=REGSWIZ
PATTERN   : KVV 0x76 V66 V0F  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1  SWIZ=0
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd
}
{
ICLASS    : VPCMPGTD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
COMMENT   : NO ROUNDING FORM
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x66 V66 V0F  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT32()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x66 V66 V0F  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd:TXT=REGSWIZ
PATTERN   : KVV 0x66 V66 V0F  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1  SWIZ=0
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd
}
{
ICLASS    : VPCMPLTD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
COMMENT   : NO ROUNDING FORM
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x74 V66 V0F38  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT32()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x74 V66 V0F38  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd:TXT=REGSWIZ
PATTERN   : KVV 0x74 V66 V0F38  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1  SWIZ=0
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd
}
{
ICLASS    : VPTESTMD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
COMMENT   : NO ROUNDING FORM
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x27 V66 V0F38  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM()  UPCONVERT_INT32()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x27 V66 V0F38  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd:TXT=REGSWIZ
PATTERN   : KVV 0x27 V66 V0F38  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1  SWIZ=0
OPERANDS  : REG0=MASK_R():w:mskw REG1=MASK1():r:mskw REG2=ZMM_N3():r:zd REG3=ZMM_B3():r:zd
}






{
ICLASS    : VPACKSTOREHD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES :  KNC_FP MXCSR  MASKADDR KNC_I32 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX # FIXME: MEMONLY???

# store to memory
PATTERN   : KVV 0xD4 V66 V0F38  W0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_INT32()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zd NO_SCALE_DISP8=1
}
{
ICLASS    : VPACKSTORELD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES :  KNC_FP MXCSR  MASKADDR KNC_I32 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX # FIXME: MEMONLY???

# store to memory
PATTERN   : KVV 0xD0 V66 V0F38  W0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_INT32()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zd NO_SCALE_DISP8=1
}

{
ICLASS    : VPACKSTOREHPD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES :  KNC_FP MXCSR  MASKADDR KNC_F64 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX # FIXME: MEMONLY???

# store to memory
PATTERN   : KVV 0xD5 V66 V0F38  W1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_FLT64()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zf64 NO_SCALE_DISP8=1
}
{
ICLASS    : VPACKSTORELPD
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES :  KNC_FP MXCSR  MASKADDR KNC_F64 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX # FIXME: MEMONLY???

# store to memory
PATTERN   : KVV 0xD1 V66 V0F38  W1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_FLT64()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zf64 NO_SCALE_DISP8=1
}

{
ICLASS    : VPACKSTOREHPS
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES :  KNC_FP MXCSR  MASKADDR KNC_F32 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX # FIXME: MEMONLY???

# store to memory
PATTERN   : KVV 0xD5 V66 V0F38  W0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_FLT32()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zf32 NO_SCALE_DISP8=1
}
{
ICLASS    : VPACKSTORELPS
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES :  KNC_FP MXCSR  MASKADDR KNC_F32 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX # FIXME: MEMONLY???

# store to memory
PATTERN   : KVV 0xD1 V66 V0F38  W0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_FLT32()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zf32 NO_SCALE_DISP8=1
}

{
ICLASS    : VPACKSTOREHQ
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES :  KNC_FP MXCSR  MASKADDR KNC_I64 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX # FIXME: MEMONLY???

# store to memory
PATTERN   : KVV 0xD4 V66 V0F38  W1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_INT64()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zq NO_SCALE_DISP8=1
}
{
ICLASS    : VPACKSTORELQ
CPL       : 3
CATEGORY  : DATAXFER
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES :  KNC_FP MXCSR  MASKADDR KNC_I64 NO_SCALE_DISP8 AGEN_PACK SPECIAL_AGEN_REQUIRED MASKOP_EVEX # FIXME: MEMONLY???

# store to memory
PATTERN   : KVV 0xD0 V66 V0F38  W1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() DNCONVERT_INT64()
OPERANDS  : MEM0:w:zv:TXT=CONVERT:TXT=NT  REG0=MASK1():r:mskw   REG1=ZMM_R3():r:zq NO_SCALE_DISP8=1
}



################
# v4 template
#




{
ICLASS    : VEXP223PS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : NOSWIZ REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xC8 V0F38 V66  W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() NOSWIZF32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  MEM0:r:zd:TXT=NT

PATTERN   : KVV 0xC8 V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd:TXT=SAEC

PATTERN   : KVV 0xC8 V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd
}
{
ICLASS    : VLOG2PS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : NOSWIZ REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xC9 V0F38 V66  W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() NOSWIZF32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  MEM0:r:zd:TXT=NT

PATTERN   : KVV 0xC9 V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd:TXT=SAEC

PATTERN   : KVV 0xC9 V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd
}
{
ICLASS    : VRCP23PS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : NOSWIZ REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xCA V0F38 V66  W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() NOSWIZF32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  MEM0:r:zd:TXT=NT

PATTERN   : KVV 0xCA V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd:TXT=SAEC

PATTERN   : KVV 0xCA V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd
}
{
ICLASS    : VRSQRT23PS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : NOSWIZ REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xCB V0F38 V66  W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() NOSWIZF32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  MEM0:r:zd:TXT=NT

PATTERN   : KVV 0xCB V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd:TXT=SAEC

PATTERN   : KVV 0xCB V0F38 V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] NR=0 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd
}




#################
# v5  template - some have imm8
#


# two opnd, int32 src,  no round, noevsr,

# two opnd, int32 src,  no round, noevsr,  imm8


{
ICLASS    : VCVTFXPNTDQ2PS
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xCB V0F3A VNP  W0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b


PATTERN   : KVV 0xCB V0F3A VNP  W0 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd:TXT=REGSWIZ  IMM0:r:b
PATTERN   : KVV 0xCB V0F3A VNP  W0 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1  KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zd:TXT=SAEC IMM0:r:b
}

# two opnd, flt32 src,  round, noevsr,


# two opnd, flt64 src,  round, noevsr



{
ICLASS    : VCVTPD2PS
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES: KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x5A V0F V66  W1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

PATTERN   : KVV 0x5A V0F V66  W1 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=REGSWIZ
PATTERN   : KVV 0x5A V0F V66  W1 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn]  NR=1 ROUND() KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=ROUNDC:TXT=SAEC
}





{
ICLASS    : VCVTFXPNTPD2DQ
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES: KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0xE6 V0F3A VF2  W1 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

PATTERN   : KVV 0xE6 V0F3A VF2  W1 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=REGSWIZ  IMM0:r:b
PATTERN   : KVV 0xE6 V0F3A VF2  W1 NOEVSR MOD[0b11] MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=SAEC IMM0:r:b
}







{
ICLASS    : VCVTFXPNTUDQ2PS
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES :  REQUIRES_ALIGNMENT MASKOP_EVEX
COMMENT   : FIXME: ROUNDING MODE comes from SSS[1:0] but not used for direct input rounding. FIXME: Not disallowing  SWIZ=1xx

PATTERN   : KVV 0xCA V0F3A VNP  W0 NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

PATTERN   : KVV 0xCA V0F3A VNP  W0 NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zud:TXT=REGSWIZ IMM0:r:b

PATTERN   : KVV 0xCA V0F3A VNP  W0 NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zud:TXT=SAEC IMM0:r:b
}







{
ICLASS    : VGETMANTPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES: KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x26 V0F3A V66  W1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0x26 V0F3A V66  W1  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=SAEC  IMM0:r:b

PATTERN   : KVV 0x26 V0F3A V66  W1  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64 IMM0:r:b
}
{
ICLASS    : VCVTFXPNTPD2UDQ
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES: KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xCA V0F3A VF2  W1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zud REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0xCA V0F3A VF2  W1  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zud REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=SAEC  IMM0:r:b

PATTERN   : KVV 0xCA V0F3A VF2  W1  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zud REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64 IMM0:r:b
}
{
ICLASS    : VRNDFXPNTPD
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ATTRIBUTES: KNC_FP MXCSR  KNC_F64 REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x52 V0F3A V66  W1  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0x52 V0F3A V66  W1  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64:TXT=SAEC  IMM0:r:b

PATTERN   : KVV 0x52 V0F3A V66  W1  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE64()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():r:mskw REG2=ZMM_B3():r:zf64 IMM0:r:b
}


{
ICLASS    : VGETMANTPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES: KNC_FP MXCSR REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x26 V0F3A V66  W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0x26 V0F3A V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=SAEC  IMM0:r:b

PATTERN   : KVV 0x26 V0F3A V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=REGSWIZ IMM0:r:b
}
{
ICLASS    : VCVTFXPNTPS2DQ
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES: KNC_FP MXCSR REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xCB V0F3A V66  W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0xCB V0F3A V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=SAEC  IMM0:r:b

PATTERN   : KVV 0xCB V0F3A V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=REGSWIZ IMM0:r:b
}
{
ICLASS    : VCVTFXPNTPS2UDQ
CPL       : 3
CATEGORY  : CONVERT
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES: KNC_FP MXCSR REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0xCA V0F3A V66  W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zud REG1=MASK1():r:mskw  MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0xCA V0F3A V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zud REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=SAEC  IMM0:r:b

PATTERN   : KVV 0xCA V0F3A V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zud REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=REGSWIZ IMM0:r:b
}
{
ICLASS    : VRNDFXPNTPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES: KNC_FP MXCSR REQUIRES_ALIGNMENT MASKOP_EVEX

PATTERN   : KVV 0x52 V0F3A V66  W0  NOEVSR MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() UPCONVERT_FLT32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  MEM0:r:zv:TXT=CONVERT:TXT=NT IMM0:r:b

# It does not ROUND
PATTERN   : KVV 0x52 V0F3A V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=1 KNC_SAE()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=SAEC  IMM0:r:b

PATTERN   : KVV 0x52 V0F3A V66  W0  NOEVSR MOD[0b11]  MOD=3 REG[rrr] RM[nnn] UIMM8() NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw  REG2=ZMM_B3():r:zf32:TXT=REGSWIZ IMM0:r:b
}


#################
# v6  template -- srd/dst swappage
#

{
ICLASS    : VGATHERDPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : KNC_GATHER KNC_F64 gather REQUIRES_ALIGNMENT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0x92 V66 V0F38  W1 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[rrr] RM[0b100] KNC_VMODRM() UPCONVERT_FLT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf64 REG1=MASK1():rw:mskw  MEM0:r:zv:TXT=NT:TXT=CONVERT NELEM=1:SUPP
}
{
ICLASS    : VGATHERDPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : KNC_GATHER KNC_F32 gather REQUIRES_ALIGNMENT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0x92 V66 V0F38  W0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[rrr] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():rw:mskw  MEM0:r:zv:TXT=NT:TXT=CONVERT NELEM=1:SUPP
}
{
ICLASS    : VPGATHERDD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : KNC_GATHER KNC_I32 gather REQUIRES_ALIGNMENT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0x90 V66 V0F38  W0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[rrr] RM[0b100] KNC_VMODRM() UPCONVERT_INT32_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():rw:mskw  MEM0:r:zv:TXT=NT:TXT=CONVERT NELEM=1:SUPP
}
{
ICLASS    : VPGATHERDQ
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : KNC_GATHER KNC_I64 gather REQUIRES_ALIGNMENT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0x90 V66 V0F38  W1 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[rrr] RM[0b100] KNC_VMODRM() UPCONVERT_INT64_LOAD()
OPERANDS  : REG0=ZMM_R3():rw:zq REG1=MASK1():rw:mskw  MEM0:r:zv:TXT=NT:TXT=CONVERT NELEM=1:SUPP
}



{
ICLASS    : VPSCATTERDD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : KNC_SCATTER KNC_I32 scatter REQUIRES_ALIGNMENT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xA0 V66 V0F38  W0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[rrr] RM[0b100] KNC_VMODRM() DNCONVERT_INT32()
OPERANDS  : MEM0:w:zv:TXT=NT:TXT=CONVERT  REG1=MASK1():rw:mskw   REG0=ZMM_R3():r:zd NELEM=1:SUPP
}
{
ICLASS    : VPSCATTERDQ
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : KNC_SCATTER KNC_I64 scatter REQUIRES_ALIGNMENT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xA0 V66 V0F38  W1 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[rrr] RM[0b100] KNC_VMODRM() DNCONVERT_INT64()
OPERANDS  : MEM0:w:zv:TXT=NT:TXT=CONVERT  REG1=MASK1():rw:mskw   REG0=ZMM_R3():r:zq NELEM=1:SUPP
}
{
ICLASS    : VSCATTERDPD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : KNC_SCATTER KNC_F64 scatter REQUIRES_ALIGNMENT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xA2 V66 V0F38  W1 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[rrr] RM[0b100] KNC_VMODRM() DNCONVERT_FLT64()
OPERANDS  : MEM0:w:zv:TXT=NT:TXT=CONVERT  REG1=MASK1():rw:mskw   REG0=ZMM_R3():r:zf64 NELEM=1:SUPP
}
{
ICLASS    : VSCATTERDPS
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ISA_SET   : KNCE
ATTRIBUTES : KNC_SCATTER KNC_F32 scatter REQUIRES_ALIGNMENT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xA2 V66 V0F38  W0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[rrr] RM[0b100] KNC_VMODRM() DNCONVERT_FLT32()
OPERANDS  : MEM0:w:zv:TXT=NT:TXT=CONVERT  REG1=MASK1():rw:mskw   REG0=ZMM_R3():r:zf32 NELEM=1:SUPP
}



#################
# v7  template
#





{
ICLASS    : VPADCD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX

# load from memory
PATTERN   : KVV 0x5C  V0F38 V66  W0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register  swizzle
PATTERN   : KVV 0x5C  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd:TXT=REGSWIZ

# no round on reg/reg version
PATTERN   : KVV 0x5C  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd
}

{
ICLASS    : VPSBBD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX

# load from memory
PATTERN   : KVV 0x5E  V0F38 V66  W0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register  swizzle
PATTERN   : KVV 0x5E  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd:TXT=REGSWIZ

# no round on reg/reg version
PATTERN   : KVV 0x5E  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd
}
{
ICLASS    : VPSBBRD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX

# load from memory
PATTERN   : KVV 0x6E  V0F38 V66  W0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register  swizzle
PATTERN   : KVV 0x6E  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd:TXT=REGSWIZ

# no round on reg/reg version
PATTERN   : KVV 0x6E  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd
}
{
ICLASS    : VPSUBRSETBD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX

# load from memory
PATTERN   : KVV 0x6F  V0F38 V66  W0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register  swizzle
PATTERN   : KVV 0x6F  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd:TXT=REGSWIZ

# no round on reg/reg version
PATTERN   : KVV 0x6F  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd
}
{
ICLASS    : VPSUBSETBD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX

# load from memory
PATTERN   : KVV 0x5F  V0F38 V66  W0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register  swizzle
PATTERN   : KVV 0x5F  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd:TXT=REGSWIZ

# no round on reg/reg version
PATTERN   : KVV 0x5F  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd
}

# writes the mask...
{
ICLASS    : VPADDSETCD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : REQUIRES_ALIGNMENT MASKOP_EVEX
COMMENT   : strange: writes a 2nd mask and reads the dest as a real source.
# load from memory
PATTERN   : KVV 0x5D  V0F38 V66  W0  MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UPCONVERT_INT32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw MEM0:r:zv:TXT=CONVERT:TXT=NT

# load from register  swizzle
PATTERN   : KVV 0x5D  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0 REG_SWIZZLE32()
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd:TXT=REGSWIZ

# no round on reg/reg version
PATTERN   : KVV 0x5D  V0F38 V66  W0  MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=1 SWIZ=0
OPERANDS  : REG0=ZMM_R3():rw:zd REG1=MASK1():r:mskw  REG2=MASK_N():w:mskw  REG3=ZMM_B3():r:zd
}

#################
# v8  template
#




{
ICLASS    : VALIGND
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : NOSWIZ REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x03 V0F3A V66  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() UIMM8() NOSWIZD()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zd:TXT=NT IMM0:r:b

PATTERN   : KVV 0x03 V0F3A V66  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0  UIMM8() SWIZ=0 
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32 IMM0:r:b
}
{
ICLASS    : VPERMD
CPL       : 3
CATEGORY  : KNC
EXTENSION : KNCE
ATTRIBUTES : NOSWIZ REQUIRES_ALIGNMENT MASKOP_EVEX
PATTERN   : KVV 0x36 V0F38 V66  W0 MOD[mm]  MOD!=3 REG[rrr] RM[nnn] MODRM() NOSWIZD()
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 MEM0:r:zd:TXT=NT

PATTERN   : KVV 0x36 V0F38 V66  W0 MOD[0b11] MOD=3 REG[rrr] RM[nnn] NR=0  SWIZ=0 
OPERANDS  : REG0=ZMM_R3():rw:zf32 REG1=MASK1():r:mskw REG2=ZMM_N3():r:zf32 REG3=ZMM_B3():r:zf32
}

#################
# v9  template


{
ICLASS    : VGATHERPF0DPS
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ATTRIBUTES : KNC_GATHER PREFETCH  SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xC6 V0F38 V66  REXW=0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[0b001] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  :  MEM0:r:zv:TXT=NT REG0=MASK1():rw:mskw
COMMENT   : the upconvert is only to set the element size for disp8*N in the base address
}

{
ICLASS    : VGATHERPF1DPS
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ATTRIBUTES : KNC_GATHER PREFETCH SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xC6 V0F38 V66  REXW=0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[0b010] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  :  MEM0:r:zv:TXT=NT REG0=MASK1():rw:mskw
COMMENT   : the upconvert is only to set the element size for disp8*N in the base address
}


{
ICLASS    : VGATHERPF0HINTDPD
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET   : KNC_PF_HINT
ATTRIBUTES : KNC_GATHER PREFETCH SPARSEHINT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xC6 V0F38 V66  REXW=1 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[0b000] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  :  MEM0:r:zv:TXT=NT REG0=MASK1():rw:mskw
COMMENT   : the upconvert is only to set the element size for disp8*N in the base address
}

{
ICLASS    : VGATHERPF0HINTDPS
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET   : KNC_PF_HINT
ATTRIBUTES : KNC_GATHER PREFETCH SPARSEHINT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xC6 V0F38 V66  REXW=0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[0b000] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  :  MEM0:r:zv:TXT=NT REG0=MASK1():rw:mskw
COMMENT   : the upconvert is only to set the element size for disp8*N in the base address
}


{
ICLASS    : VSCATTERPF0DPS
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ATTRIBUTES : KNC_SCATTER PREFETCH SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xC6 V0F38 V66  REXW=0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[0b101] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  :  MEM0:w:zv:TXT=NT REG0=MASK1():rw:mskw
COMMENT   : the upconvert is only to set the element size for disp8*N in the base address
}

{
ICLASS    : VSCATTERPF1DPS
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ATTRIBUTES : KNC_SCATTER PREFETCH SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xC6 V0F38 V66  REXW=0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[0b110] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  :  MEM0:w:zv:TXT=NT REG0=MASK1():rw:mskw
COMMENT   : the upconvert is only to set the element size for disp8*N in the base address
}



{
ICLASS    : VSCATTERPF0HINTDPD
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET   : KNC_PF_HINT
ATTRIBUTES : KNC_SCATTER PREFETCH SPARSEHINT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xC6 V0F38 V66  REXW=1 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[0b100] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  :  MEM0:w:zv:TXT=NT REG0=MASK1():rw:mskw
COMMENT   : the upconvert is only to set the element size for disp8*N in the base address
}


{
ICLASS    : VSCATTERPF0HINTDPS
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET   : KNC_PF_HINT
ATTRIBUTES : KNC_SCATTER PREFETCH SPARSEHINT SPECIAL_AGEN_REQUIRED MASKOP_EVEX
PATTERN   : KVV 0xC6 V0F38 V66  REXW=0 NO_SPARSE_EVSR MOD[mm] MOD!=3 REG[0b100] RM[0b100] KNC_VMODRM() UPCONVERT_FLT32_LOAD()
OPERANDS  :  MEM0:w:zv:TXT=NT REG0=MASK1():rw:mskw
COMMENT   : the upconvert is only to set the element size for disp8*N in the base address
}


######################################################################
## EVEX versions of the CLEVECT* and VPREFETCH* NI
######################################################################


{
ICLASS    : CLEVICT0_EVEX
DISASM    : clevict0
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0xAE  VL512 VF2 V0F  NOEVSR MOD[mm] MOD!=3 REG[0b111] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch  
IFORM     : CLEVICT0_EVEX_MEMmprefetch_EVEX
}
{
ICLASS    : CLEVICT1_EVEX
DISASM    : clevict1
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0xAE  VL512 VF3 V0F  NOEVSR MOD[mm] MOD!=3 REG[0b111] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch  
IFORM     : CLEVICT1_EVEX_MEMmprefetch_EVEX
}



{
ICLASS    : VPREFETCH0_EVEX
DISASM    : vprefetch0
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0x18  VL512 VNP V0F  NOEVSR MOD[mm] MOD!=3 REG[0b001] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch
IFORM     : VPREFETCH0_EVEX_MEMmprefetch_EVEX
}
{
ICLASS    : VPREFETCH1_EVEX
DISASM    : vprefetch1
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0x18  VL512 VNP V0F  NOEVSR MOD[mm] MOD!=3 REG[0b010] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch
IFORM     : VPREFETCH1_EVEX_MEMmprefetch_EVEX
}
{
ICLASS    : VPREFETCH2_EVEX
DISASM    : vprefetch2
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0x18  VL512 VNP V0F  NOEVSR MOD[mm] MOD!=3 REG[0b011] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch
IFORM     : VPREFETCH2_EVEX_MEMmprefetch_EVEX
}
{
ICLASS    : VPREFETCHE0_EVEX
DISASM    : vprefetche0
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0x18  VL512 VNP V0F  NOEVSR MOD[mm] MOD!=3 REG[0b101] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch
IFORM     : VPREFETCHE0_EVEX_MEMmprefetch_EVEX
}
{
ICLASS    : VPREFETCHE1_EVEX
DISASM    : vprefetche1
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0x18  VL512 VNP V0F  NOEVSR MOD[mm] MOD!=3 REG[0b110] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch
IFORM     : VPREFETCHE1_EVEX_MEMmprefetch_EVEX
}
{
ICLASS    : VPREFETCHE2_EVEX
DISASM    : vprefetche2
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0x18  VL512 VNP V0F  NOEVSR MOD[mm] MOD!=3 REG[0b111] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch
IFORM     : VPREFETCHE2_EVEX_MEMmprefetch_EVEX
}
{
ICLASS    : VPREFETCHENTA_EVEX
DISASM    : vprefetchenta
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0x18  VL512 VNP V0F  NOEVSR MOD[mm] MOD!=3 REG[0b100] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch
IFORM     : VPREFETCHENTA_EVEX_MEMmprefetch_EVEX
}
{
ICLASS    : VPREFETCHNTA_EVEX
DISASM    : vprefetchnta
CPL       : 3
CATEGORY  : PREFETCH
EXTENSION : KNCE
ISA_SET:    KNCE
ATTRIBUTES : PREFETCH MASKOP_EVEX
PATTERN   : KVV 0x18  VL512 VNP V0F  NOEVSR MOD[mm] MOD!=3 REG[0b000] RM[nnn]  MODRM() NOSWIZD()
OPERANDS  : MEM0:r:mprefetch
IFORM     : VPREFETCHNTA_EVEX_MEMmprefetch_EVEX
}

